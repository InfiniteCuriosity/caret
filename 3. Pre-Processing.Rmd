---
title: "3. Pre-Processing using caret"
author: "Russ Conte"
date: "4/30/2022"
output: html_document
---

`caret` includes several functions to pre-process the predictor data. It assumes that all of the data are numeric (i.e. factors have been converted to dummy variables via `model.matrix`, `dummyVars`, or other means.)

### 3.1 Creating Dummy Variables

The function `dummyVars` can be used to generate a complete (less than full rank parameterized) set of dummy variables from one or more factors. The function takes a formula and a data set and outputs an object that can be used to create the dummy variables using the predict method.

For example, the `etitanic` data set in the <span style="color:blue">`earth`</span> package includes two factors: `pclass` (passenger class, with levels 1st, 2nd, and 3rd) and `sex` (with levels female, male).

Let's load all the packages in two lines of code:

```{r}
Packages = c("AppliedPredictiveModeling", "caret", "tidyverse", "e1071", "earth")
lapply(Packages, library, character.only = TRUE)
```

Using `dummyVars`:

```{r Using dummyVars to create dummy variables in the titanic data set}

dummies <- dummyVars(survived~., data = etitanic)
head(predict(dummies, newdata = etitanic))

```

The authors point out there is no intercept, and each factor has a dummy variable for each level. This may not be useful for some modeling situations, such as `lm`.

Same idea, using the diamonds data set from tidyverse

```{r Creating dummy variables using the diamonds data set from tidyverse}

dummies <- dummyVars(price~., data = diamonds)
head(predict(dummies, newdata = diamonds))

```


### 3.2 Zero and Near Zero Variance Predictors

In some situations, the data generating mechanism can create predictors that only have a single unique value (i.e. a "zero-variance predictor"). For many models (excluding tree-based models) this may cause the model to crash or the fit to be unstable.

In a similar way, predictors might have only a handful of unique values that occur with very low frequencies. An example is the mdrr data set, and the `nR11` descriptor (number of 11-membered rings):

```{r}

data(mdrr)
data.frame(table(mdrrDescr$nR11))
```

The concern here is that these predictors may become zero–variance predictors when the data are split into cross – validation/bootstrap sub–summaries or that a few samples may have an undo influence on the model. These "nearest – zero – variance "predictors may need to be identified and eliminated prior to modeling.

To identify these types of predictors, the following two metrics can be calculated:

- The frequency of the most prevalent value over the second most frequent value left process (called the "frequency ratio"), which would be near one for while behaved predictors and very large for highly balanced data and
- The "percentage of unique values" is the Number of unique value divided by the total number of samples parentheses times 100) zero as a granularity of the data increases.

If the frequency ratio was greater than a pre-specified threshold and the unique value percentage is less than a threshold, we might consider a predictor to be near zero variance.

We would not want to false the identify data that have low granularity but are evenly distributed, such a from a discreet uniform distribution. Using both criteria should not false detect such predictors.

Looking at the MDRR data, the `nearZeroVar` function can be used to identify near zero-variance variables (the `saveMetrics` argument can be used to show the details and usually defaults to `FALSE`)


```{r Applying the `nearZeroVar` function to identify near-zero-variance variables}

nzv <- nearZeroVar(mdrrDescr, saveMetrics = TRUE)
nzv[nzv$nzv,][1:10,]

```

```{r}

nzv <- nearZeroVar(mdrrDescr)
filteredDescr <- mdrrDescr[, -nzv]
dim(filteredDescr)

```


Let's use the tidyverse to find the predictors with the lowest variance:

```{r Tidyverse to find predictors with the lowest variance in the MDRR data set}

mdrrDescr %>% 
  summarise(across(where(is.numeric), var)) %>% 
  pivot_longer(everything()) %>% 
  arrange(value)

```


By default `nearZeroVar` will return the positions of the variables that are flagged to be problems.

### 3.3 Identifying Correlated Predictors

Given a correlation matrix, the `findCorrelation` function uses the following algorithm to flag predictors for removal:

```{r Identify and remove correlated predictors}

descrCor <- cor(filteredDescr)
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > 0.999)

```

For the previous MDRR data, there are 65 descriptors that are almost perfectly correlated (correlation greater than 0.99), such as the total information index of composition (`IAC`) and the total information contact index (neighborhood symmetry of zero-order) (`TIC0`) (correlation equals one). The code chunk below shows the effect of removing the descriptors with absolute correlations above 0.75

```{r Remove features correlated above 0.75}

descrCor <- cor(filteredDescr)
summary(descrCor[upper.tri(descrCor)])

```

```{r}

highlyCorDescr <- findCorrelation(descrCor, cutoff = 0.75)
filteredDescr <- filteredDescr[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr)
summary(descrCor2[upper.tri(descrCor2)])

```

## Linear Dependencies

The function `findlinearCombos` uses the QR decomposition of a matrix to enumerate sets of linear combinations (if they exist). For example, consider the following metrics that could have been produced by less than full rank parameterization of a two-way experimental layout:

```{r Linear Dependencies 1}

ltfrDesign <- matrix(0, nrow=6, ncol=6)
ltfrDesign[,1] <- c(1, 1, 1, 1, 1, 1)
ltfrDesign[,2] <- c(1, 1, 1, 0, 0, 0)
ltfrDesign[,3] <- c(0, 0, 0, 1, 1, 1)
ltfrDesign[,4] <- c(1, 0, 0, 1, 0, 0)
ltfrDesign[,5] <- c(0, 1, 0, 0, 1, 0)
ltfrDesign[,6] <- c(0, 0, 1, 0, 0, 1)

```

Note that columns two and three add up to the first column. Similarly, columns four, five and six and up to the first column. `findlinearCombos` will return a list that enumerates these dependencies. for each linear combination, it will incrementally remove columns from the matrix and test to see if the dependencies have been resolved. `findlinearCombos` will also return of vector of column positions which can be removed to eliminate linear dependencies:

```{r Remove lineard dependencies 2}

comboInfo <- findLinearCombos(ltfrDesign)
comboInfo

```

```{r Remove linear dependencies}

ltfrDesign[,-comboInfo$remove]

```

These types of dependencies can arise when large numbers of binary chemical fingerprints are used to describe the structure of a molecule.

## 3.5 The `preProcess` Function

The `preProcess` class can be used for many operations on predictors, including centering and scaling. The function `preProcess` estimates the required parameters for each operation and `predict.preProcess` is used to apply them to specific data sets. This function can also be interfaced when calling the `train` function.

Several types of techniques are described in the next few sections and then another example is used to demonstrate how multiple methods can be used. Note that, in all cases, the `preprocess` function estimates whatever it requires from a specific data set (e.g. the training set) and applies these transformations to *any* data set without recomputing the values.

## 3.6 Centering and Scaling

In the example below, the half of the MDRR data are used to estimate the location and scale of the predictors. The function `preProcess` doesn't actually pre-process the data. `predict.preProcess` is used to pre-process this and other data sets.

```{r pre-process the MDRR data}

set.seed(96)
inTrain <- sample(seq(along = mdrrClass), length(mdrrClass)/2)

training <- filteredDescr[inTrain,]
test <- filteredDescr[-inTrain,]
trainMDRR <- mdrrClass[inTrain]
testMDRR <- mdrrClass[-inTrain]

preProcValues <- preProcess(training, method = c("center", "scale"))

trainTransformed <- predict(preProcValues, training)
testTransformed <- predict(preProcValues, test)

```

Let's look at the results:

```{r Look at the results of Centering and Scaling the MDRR data set}

mdrrClass[1:10]

inTrain[1:10]

training[1:10,]

test[1:10,]

trainMDRR[1:10]

testMDRR[1:10]

preProcValues

trainTransformed[1:10,]

testTransformed[1:10,]
```

Let's do the same with the MPG data set from Tidyverse

```{r Center and scale with the MPG data set from tidyverse}

mpg <- mpg %>% 
  mutate(id = row_number())

# training set:

train1 <- mpg %>% 
  sample_frac(size = 0.5)

test1 <- mpg[-train1$id,]

preProcValue1 <- preProcess(x = train1, method = c("center", "scale"))

train1Transformed <- predict(preProcValue1, train1)
test1Transformed <- predict(preProcValue1, test1)

train1Transformed
test1Transformed
```

## 3.7 Imputation

`preProcess` can be used to impute data sets based only on information in the training set. One method of doing this is with K-nearest neighbors. For an arbitrary sample, the K closest neighbors are found in the training set and the value of the predictor is imputed using these values (e. g. Using the mean).Using this approach will automatically trigger `pre-process` to center and scale the data, regardless of what is in the `method` argument. Alternatively, bagged trees can also be used to impute. For each predictor in the data, a bagged tree is created using all of the other predictors in the training set. When a new sample has a missing predictor value, the bagged model is used to predict the value. While, in theory, this is a more powerful method of imputing, the computational costs are much higher than the nearest neighbor technique.

## 3.8 Transforming Predictors

In some cases, there is a need to use principal component analysis (PCA) to transform the data to a smaller sub – space where the new variables are uncorrelated with one another. The back tick pre-process backed class can be applied as transformation by using the ` "PCA quote ` in the ` method ` argument. Doing this will also for scaling of the predictors. Note that when PCA is requested, ` predict that preprocess ` change the column names to ` PC1 `, ` PC 2`, and sev.

Similarly, independent component analysis (ICE) can also be used to find new variables that are linear combinations of the original set such that the components are independent (as opposed to uncorrelated in PCA). The new variables will be labeled as ` IC 1 `, ` IC 2`, and so on.

The "special sign" transformation (Serneels at all, 2006) projects the data for a predictor to the unit circle in p dimensions, where p is the number of predictors. Essentially, a vector of data is divided by its norm. The two figures below show two centered and scale descriptors from the MDRR data before an after the special sign transformation. The predictors should be centered and scaled before applying this transformation.

```{r Transforming Predictors}

transparentTheme(trans = 0.4)

plotSubset <-  data.frame(scale(mdrrDescr[, c("nC", "X4v")]))
xyplot(nC ~ X4v,
       data = plotSubset,
       groups = mdrrClass,
       auto.key = list(columns = 2))

```

Let's do the same transforming predictors with the MPG data set:

```{r Transforming predictors with the MPG data set}

class1 <- mpg$class
transparentTheme(trans = 0.4)
plotSubset1 <- data.frame(scale(mpg[,c("displ", "cty")]))
xyplot(cty~displ,
       data = plotSubset1,
       groups = class1,
       auto.key = list(columns = 3))

```

After the spatial sign:

```{r After the spatial sign}

transformed <- spatialSign(plotSubset)
transformed <- as.data.frame(transformed)
xyplot(nC ~ X4v,
       data = transformed,
       groups = mdrrClass,
       auto.key = list(columns = 2))

```

Perform spatial sign with the mpg data set from tidyverse:

```{r Spatial sign with the mpg data set from tidyverse}

transformed1 <- spatialSign(plotSubset1)
transformed1 <- as.data.frame(transformed1)
xyplot(cty ~ displ,
       data = transformed1,
       groups = class1,
       auto.key = list(columns = 2))

```

Another option, `"BoxCox"` will estimate a Box–Cox transformation on the predictors of the data are greater than zero.

```{r Box-Cox transformtion on data greater than zero}

preProcValues2 <- preProcess(training, method = "BoxCox")
trainBC <- predict(preProcValues2, training)
testBC <- predict(preProcValues2, test)
preProcValues2

```

The`NA` values correspond to the predictors that could not be transformed. This transformation requires the data to be greater than zero. Two similar transformation, the Yeo-Johnson and exponential transformation of Manly (1976) can also be used in `preProcess`

## 3.9 Putting It All Together

In *Applied Predictive Modeling* there is a case study where the execution times of jobs in a high performance environment are being predicted. The data are:

```{r Execution times of jobs in a high performance computing environment}

data("schedulingData")
str(schedulingData)

```

The data are mix of categorical and numerical predictors. Suppose we want to use the Yeo – Johnson transformation on the continuous predictors then center and scale them. Let's also suppose that we will be running a tree–based model so we might want to keep the factors as factors (as opposed to creating dummy variables). We run the function on all the columns except the last, which is the outcome.

```{r Yeo-Johnson transformation on execution times in a high performance computing environment}

pp_hpc <- preProcess(schedulingData[,-8],
                     method = c("center", "scale", "YeoJohnson"))
pp_hpc

```

The two predictors labeled as "ignored "in the output are the two factor predictors. These are not altered but the numeric protectors are transformed. However, the predictor for the number of pending jobs, has a very sparse and unbalanced distribution:

```{r mean of the number of pending jobs}

mean(schedulingData$NumPending == 0)

```

For some other models, this might be an issue (especially if we re-sample or down-sample the data). We can add a filter to check for zero- or near zero-variance predictors prior to running the pre-processing calculations:

```{r Checking for zero or near zero variance}

pp_no_nzv <- preProcess(schedulingData[,-8],
                        method = c("center", "scale", "YeoJohnson", "nzv"))
pp_no_nzv

```

Note that one predictor is labeled as "removed" and the processed data lack the sparse predictor.

## 3.10 Class Distance Calculations

`caret` contains functions to generate new predictor variables based on distances to class centroid's (parenthesis) similar to how linear discriminate analysis works). For each level of a factor variable, the class centroid and covariance matrix is calculated. For new samples the Mahalanobis distance to each of the class centroids is computed and can be used as an additional predictor. This can be useful for nonlinear models when the true decision bottle boundary is actually linear.

In cases where there are more predictors within a class than samples, the `classDist` function has arguments called `pca` and `keep` arguments that allow for principal components analysis within each class to be used to avoid issues with singular covariance matrices.

`predict.classDist` is then used to generate the class distances. By default, the distances are logged, but this can changed by the `trans` argument to `predict.classDist`.

As an example we can use the MDRR data:

```{r Class Distance Calculations with the MDRR data}

centroids <- classDist(trainBC, trainMDRR)
distances <- predict(centroids, testBC)
distances <- as.data.frame(distances)
head(distances)
```

This image shows a scatterplot matrix of the class distances for held-out samples:

```{r Scatterplot for held-out samples}

xyplot(dist.Active ~ dist.Inactive,
       data = distances,
       groups = testMDRR,
       auto.key = list(columns = 2))


```

